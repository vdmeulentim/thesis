{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression with k-fold cross validation metadata only:\n",
      "\n",
      "Cross-Validation Average RMSE: 5541.026238833146\n",
      "Cross-Validation Average R-squared: -0.17056661894673444\n",
      "Cross-Validation Average MAPE: 5.906221014433543\n",
      "\n",
      "Test RMSE: 10597.912762422162\n",
      "Test R-squared: -0.14909288244989405\n",
      "Test MAPE: 3.5193315661299978\n"
     ]
    }
   ],
   "source": [
    "# Ridge regression with k-fold cross validation metadata only\n",
    "print('Ridge regression with k-fold cross validation metadata only:')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import data from Excel\n",
    "train_data = pd.read_excel(\"train_data.xlsx\")\n",
    "val_data = pd.read_excel(\"val_data.xlsx\")\n",
    "test_data = pd.read_excel(\"test_data.xlsx\")\n",
    "\n",
    "X_columns = ['sex_num', \"age\", 'videogames_hours_a_week']\n",
    "y_column = ['average_score']\n",
    "\n",
    "X_train = train_data[X_columns].values\n",
    "y_train = train_data[y_column].values.ravel()\n",
    "X_val = val_data[X_columns].values\n",
    "y_val = val_data[y_column].values.ravel()\n",
    "X_test = test_data[X_columns].values\n",
    "y_test = test_data[y_column].values.ravel()\n",
    "\n",
    "# Combine train_data and val_data\n",
    "train_val_data = pd.concat([train_data, val_data])\n",
    "X_train_val = train_val_data[X_columns].values\n",
    "y_train_val = train_val_data[y_column].values.ravel()\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Create a Ridge regressor\n",
    "regr_ridge = Ridge()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(regr_ridge, param_grid=param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "regr_ridge = grid_search.best_estimator_\n",
    "\n",
    "# K-fold cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "rmse_scores_ridge = []\n",
    "r2_scores_ridge = []\n",
    "mape_scores_ridge = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_val):\n",
    "    X_train_cv, X_test_cv = X_train_val[train_index], X_train_val[test_index]\n",
    "    y_train_cv, y_test_cv = y_train_val[train_index], y_train_val[test_index]\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr_ridge.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = regr_ridge.predict(X_test_cv)\n",
    "\n",
    "    # Evaluation\n",
    "    rmse_scores_ridge.append(np.sqrt(mean_squared_error(y_test_cv, y_pred)))\n",
    "    r2_scores_ridge.append(r2_score(y_test_cv, y_pred))\n",
    "    mape_scores_ridge.append(mean_absolute_percentage_error(y_test_cv, y_pred))\n",
    "\n",
    "# Calculate average scores\n",
    "print(\"\\nCross-Validation Average RMSE:\", np.mean(rmse_scores_ridge))\n",
    "print(\"Cross-Validation Average R-squared:\", np.mean(r2_scores_ridge))\n",
    "print(\"Cross-Validation Average MAPE:\", np.mean(mape_scores_ridge))\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = regr_ridge.predict(X_test)\n",
    "\n",
    "#Evaluate on test set\n",
    "print(\"\\nTest RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Test R-squared:\", r2_score(y_test, y_test_pred))\n",
    "print(\"Test MAPE:\", mean_absolute_percentage_error(y_test, y_test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance (sorted from high to low):\n",
      "age: 0.5197260941139141\n",
      "videogames_hours_a_week: 0.37903739064432546\n",
      "sex_num: 0.10123651524176042\n"
     ]
    }
   ],
   "source": [
    "# Calculate feature importance using coefficients\n",
    "feature_importance = np.abs(regr_ridge.coef_)\n",
    "\n",
    "# Normalize the feature importances\n",
    "normalized_feature_importance = feature_importance / np.sum(feature_importance)\n",
    "\n",
    "# Create a dictionary of feature names and their corresponding importances\n",
    "feature_importance_dict = dict(zip(X_columns, normalized_feature_importance))\n",
    "\n",
    "# Sort the dictionary by importance\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted feature importances\n",
    "print(\"\\nFeature Importance (sorted from high to low):\")\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression with k-fold cross validation metadata only:\n",
      "\n",
      "Cross-Validation Average RMSE: 5891.11582366097\n",
      "Cross-Validation Average R-squared: -0.510539642825664\n",
      "Cross-Validation Average MAPE: 5.434534299074527\n",
      "\n",
      "Test RMSE: 11773.247868292954\n",
      "Test R-squared: -0.4181005621085354\n",
      "Test MAPE: 2.9135666960827216\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression with K-fold cross validation metadata only\n",
    "print('Lasso regression with k-fold cross validation metadata only:')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import data from Excel\n",
    "train_data = pd.read_excel(\"train_data.xlsx\")\n",
    "val_data = pd.read_excel(\"val_data.xlsx\")\n",
    "test_data = pd.read_excel(\"test_data.xlsx\")\n",
    "\n",
    "X_columns = ['sex_num', \"age\", 'videogames_hours_a_week']\n",
    "y_column = ['average_score']\n",
    "\n",
    "X_train = train_data[X_columns].values\n",
    "y_train = train_data[y_column].values.ravel()\n",
    "X_val = val_data[X_columns].values\n",
    "y_val = val_data[y_column].values.ravel()\n",
    "X_test = test_data[X_columns].values\n",
    "y_test = test_data[y_column].values.ravel()\n",
    "\n",
    "# Combine train_data and val_data\n",
    "train_val_data = pd.concat([train_data, val_data])\n",
    "X_train_val = train_val_data[X_columns].values\n",
    "y_train_val = train_val_data[y_column].values.ravel()\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# K-fold cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "rmse_scores_lasso = []\n",
    "r2_scores_lasso = []\n",
    "mape_scores_lasso = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_val):\n",
    "    X_train_cv, X_test_cv = X_train_val[train_index], X_train_val[test_index]\n",
    "    y_train_cv, y_test_cv = y_train_val[train_index], y_train_val[test_index]\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    }\n",
    "\n",
    "    # Create a Lasso regressor\n",
    "    regr_lasso = Lasso()\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(regr_lasso, param_grid=param_grid, cv=5, scoring='r2')\n",
    "    grid_search.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    # Train the model using the best hyperparameters\n",
    "    regr_lasso = grid_search.best_estimator_\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr_lasso.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = regr_lasso.predict(X_test_cv)\n",
    "\n",
    "    # Evaluation\n",
    "    rmse_scores_lasso.append(np.sqrt(mean_squared_error(y_test_cv, y_pred)))\n",
    "    r2_scores_lasso.append(r2_score(y_test_cv, y_pred))\n",
    "    mape_scores_lasso.append(mean_absolute_percentage_error(y_test_cv, y_pred))\n",
    "\n",
    "# Calculate average scores\n",
    "print(\"\\nCross-Validation Average RMSE:\", np.mean(rmse_scores_lasso))\n",
    "print(\"Cross-Validation Average R-squared:\", np.mean(r2_scores_lasso))\n",
    "print(\"Cross-Validation Average MAPE:\", np.mean(mape_scores_lasso))\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = regr_lasso.predict(X_test)\n",
    "\n",
    "print(\"\\nTest RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Test R-squared:\", r2_score(y_test, y_test_pred))\n",
    "print(\"Test MAPE:\", mean_absolute_percentage_error(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance (sorted from high to low):\n",
      "age: 0.599635821262581\n",
      "videogames_hours_a_week: 0.323444864393119\n",
      "sex_num: 0.0769193143443002\n"
     ]
    }
   ],
   "source": [
    "# Calculate feature importance using coefficients\n",
    "feature_importance = np.abs(regr_lasso.coef_)\n",
    "\n",
    "# Normalize the feature importances\n",
    "normalized_feature_importance = feature_importance / np.sum(feature_importance)\n",
    "\n",
    "# Create a dictionary of feature names and their corresponding importances\n",
    "feature_importance_dict = dict(zip(X_columns, normalized_feature_importance))\n",
    "\n",
    "# Sort the dictionary by importance\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted feature importances\n",
    "print(\"\\nFeature Importance (sorted from high to low):\")\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest regression with k-fold cross validation metadata only:\n",
      "\n",
      "Cross-Validation Average RMSE: 6632.604154930175\n",
      "Cross-Validation Average R-squared: -0.7881001158915367\n",
      "Cross-Validation Average MAPE: 5.88567557932327\n",
      "\n",
      "Test RMSE: 11107.896103600175\n",
      "Test R-squared: -0.2623450227888038\n",
      "Test MAPE: 2.0652435094161277\n",
      "\n",
      "Feature Importance - Random Forest:\n",
      "age                            importance: 0.530\n",
      "videogames_hours_a_week        importance: 0.337\n",
      "sex_num                        importance: 0.134\n"
     ]
    }
   ],
   "source": [
    "# Random Forest regression with k-fold cross validation metadata only\n",
    "print('Random Forest regression with k-fold cross validation metadata only:')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import data from Excel\n",
    "train_data = pd.read_excel(\"train_data.xlsx\")\n",
    "val_data = pd.read_excel(\"val_data.xlsx\")\n",
    "test_data = pd.read_excel(\"test_data.xlsx\")\n",
    "\n",
    "X_columns = ['sex_num', \"age\", 'videogames_hours_a_week']\n",
    "y_column = ['average_score']\n",
    "\n",
    "X_train = train_data[X_columns].values\n",
    "y_train = train_data[y_column].values.ravel()\n",
    "X_val = val_data[X_columns].values\n",
    "y_val = val_data[y_column].values.ravel()\n",
    "X_test = test_data[X_columns].values\n",
    "y_test = test_data[y_column].values.ravel()\n",
    "\n",
    "# Combine train_data and val_data\n",
    "train_val_data = pd.concat([train_data, val_data])\n",
    "X_train_val = train_val_data[X_columns].values\n",
    "y_train_val = train_val_data[y_column].values.ravel()\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the cumulative feature importances array\n",
    "cumulative_feature_importances = np.zeros(len(X_columns))\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "# Create a RandomForestRegressor\n",
    "regr_rf = RandomForestRegressor()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(regr_rf, param_grid=param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Train the model using the best hyperparameters\n",
    "regr_rf = grid_search.best_estimator_\n",
    "\n",
    "# K-fold cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "rmse_scores_rf = []\n",
    "r2_scores_rf = []\n",
    "mape_scores_rf = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_val):\n",
    "    X_train_cv, X_test_cv = X_train_val[train_index], X_train_val[test_index]\n",
    "    y_train_cv, y_test_cv = y_train_val[train_index], y_train_val[test_index]\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr_rf.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = regr_rf.predict(X_test_cv)\n",
    "\n",
    "    # Add the current model's feature importances to the cumulative feature importances array\n",
    "    cumulative_feature_importances += regr_rf.feature_importances_\n",
    "\n",
    "    # Evaluation\n",
    "    rmse_scores_rf.append(np.sqrt(mean_squared_error(y_test_cv, y_pred)))\n",
    "    r2_scores_rf.append(r2_score(y_test_cv, y_pred))\n",
    "    mape_scores_rf.append(mean_absolute_percentage_error(y_test_cv, y_pred))\n",
    "\n",
    "# Calculate average scores\n",
    "print(\"\\nCross-Validation Average RMSE:\", np.mean(rmse_scores_rf))\n",
    "print(\"Cross-Validation Average R-squared:\", np.mean(r2_scores_rf))\n",
    "print(\"Cross-Validation Average MAPE:\", np.mean(mape_scores_rf))\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred_rf = regr_rf.predict(X_test)\n",
    "\n",
    "# set\n",
    "print(\"\\nTest RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_pred_rf)))\n",
    "print(\"Test R-squared:\", r2_score(y_test, y_test_pred_rf))\n",
    "print(\"Test MAPE:\", mean_absolute_percentage_error(y_test, y_test_pred_rf))\n",
    "\n",
    "# Calculate the average feature importances by dividing the cumulative feature importances array by the number of folds\n",
    "average_feature_importances = cumulative_feature_importances / kf.get_n_splits()\n",
    "\n",
    "# Print the average feature importances\n",
    "feature_importances = pd.DataFrame(average_feature_importances, index=X_columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(\"\\nFeature Importance - Random Forest:\")\n",
    "for index, row in feature_importances.iterrows():\n",
    "    print(f\"{index:<30} importance: {row['importance']:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline/dummy regression with k-fold cross validation metadata only:\n",
      "\n",
      "Cross-Validation Average RMSE: 5557.865822470064\n",
      "Cross-Validation Average R-squared: -0.1704769979939511\n",
      "Cross-Validation Average MAPE: 6.161399700043671\n",
      "\n",
      "Test RMSE: 10354.493059881766\n",
      "Test R-squared: -0.09691288197550874\n",
      "Test MAPE: 3.7145358397888057\n"
     ]
    }
   ],
   "source": [
    "# Baseline/dummy regression with K-fold cross validation metadata only\n",
    "print('Baseline/dummy regression with k-fold cross validation metadata only:')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# All the data importing and preprocessing steps remain the same\n",
    "\n",
    "# K-fold cross validation\n",
    "kf = KFold(n_splits=5)\n",
    "rmse_scores_dummy = []\n",
    "r2_scores_dummy = []\n",
    "mape_scores_dummy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_val):\n",
    "    X_train_cv, X_test_cv = X_train_val[train_index], X_train_val[test_index]\n",
    "    y_train_cv, y_test_cv = y_train_val[train_index], y_train_val[test_index]\n",
    "\n",
    "    # Create a dummy regressor\n",
    "    dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    dummy_regr.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = dummy_regr.predict(X_test_cv)\n",
    "\n",
    "    # Evaluation\n",
    "    rmse_scores_dummy.append(np.sqrt(mean_squared_error(y_test_cv, y_pred)))\n",
    "    r2_scores_dummy.append(r2_score(y_test_cv, y_pred))\n",
    "    mape_scores_dummy.append(mean_absolute_percentage_error(y_test_cv, y_pred))\n",
    "\n",
    "# Calculate average scores\n",
    "print(\"\\nCross-Validation Average RMSE:\", np.mean(rmse_scores_dummy))\n",
    "print(\"Cross-Validation Average R-squared:\", np.mean(r2_scores_dummy))\n",
    "print(\"Cross-Validation Average MAPE:\", np.mean(mape_scores_dummy))\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = dummy_regr.predict(X_test)\n",
    "\n",
    "print(\"\\nTest RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Test R-squared:\", r2_score(y_test, y_test_pred))\n",
    "print(\"Test MAPE:\", mean_absolute_percentage_error(y_test, y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
